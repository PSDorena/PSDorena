{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Dict, List\n",
    "import requests\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from pprint import pprint\n",
    "from requests import get\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from env import github_token\n",
    "from env import github_username\n",
    "\n",
    "import acquire_titanic\n",
    "\n",
    "import prep\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore dataframes that are repositories that are in a github search of Titanic, and have the most starts. We pulled the top 180 repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Look at the data frame we have brought in.\n",
    "df = acquire_titanic.scrape_github_data()\n",
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of our repos do not have readme's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_readme_df = df[df.readme_contents == 'error: no README']\n",
    "no_readme_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(no_readme_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of orginal df. This keeps the original df intact\n",
    "#df_prep = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.readme_contents != 'error: no README']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = prep.prep_articles(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.clean[112]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.language.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.concat([df.language.value_counts(),\n",
    "                    df.language.value_counts(normalize=True)], axis=1)\n",
    "labels.columns = ['n', 'percent']\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = list(labels.index)\n",
    "langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = list(labels.n)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs_counts = []\n",
    "for x in range(len(counts)):\n",
    "    langs_counts.append(f'{counts[x]} {langs[x]}')\n",
    "langs_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import explore_charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_charts.donut_chart(langs_counts, list(labels.n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# explore the distribution of languages.\n",
    "plt.rc('font', size=16)\n",
    "plt.figure(figsize = (25,25))\n",
    "labels.n.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_df = df.drop(columns =(['repo', 'original', 'stemmed', 'lemmatized']))\n",
    "easy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakouts = pd.concat([easy_df.language.value_counts(),\n",
    "                    easy_df.language.value_counts(normalize=True)], axis=1)\n",
    "breakouts.columns = ['n', 'percent']\n",
    "breakouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = \" \".join(easy_df.clean)\n",
    "all_text = all_text.split()\n",
    "all_text_counts = pd.Series(all_text).value_counts()\n",
    "\n",
    "javascript_text = \" \".join(easy_df[easy_df.language == \"JavaScript\"].clean)\n",
    "javascript_text = javascript_text.split()\n",
    "javascript_text_counts = pd.Series(javascript_text).value_counts()\n",
    "\n",
    "jupyter_text = \" \".join(easy_df[easy_df.language == \"Jupyter Notebook\"].clean)\n",
    "jupyter_text = jupyter_text.split()\n",
    "jupyter_text_counts = pd.Series(jupyter_text).value_counts()\n",
    "\n",
    "python_text = \" \".join(easy_df[easy_df.language == \"Python\"].clean)\n",
    "python_text = python_text.split()\n",
    "python_text_counts = pd.Series(python_text).value_counts()\n",
    "\n",
    "java_text = \" \".join(easy_df[easy_df.language == \"Java\"].clean)\n",
    "java_text = java_text.split()\n",
    "java_text_counts = pd.Series(java_text).value_counts()\n",
    "\n",
    "cplus_text = \" \".join(easy_df[easy_df.language == \"C++\"].clean)\n",
    "cplus_text = cplus_text.split()\n",
    "cplus_text_counts = pd.Series(cplus_text).value_counts()\n",
    "\n",
    "go_text = \" \".join(easy_df[easy_df.language == \"Go\"].clean)\n",
    "go_text = go_text.split()\n",
    "go_text_counts = pd.Series(go_text).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = (pd.concat([all_text_counts, javascript_text_counts, jupyter_text_counts, python_text_counts, java_text_counts, cplus_text_counts, go_text_counts], axis=1, sort=True)\n",
    "                .set_axis(['all', 'javascript', 'jupyter', 'python', 'java', 'cplus', 'go'], axis=1, inplace=False)\n",
    "                .fillna(0)\n",
    "                .apply(lambda s: s.astype(int)))\n",
    "word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts.sort_values(by='all', ascending=False\n",
    "                       ).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([word_counts[word_counts.javascript == 0].sort_values(by='javascript').tail(6),\n",
    "           word_counts[word_counts.jupyter == 0].sort_values(by='jupyter').tail(6),\n",
    "          word_counts[word_counts.python == 0].sort_values(by='python').tail(6),\n",
    "           word_counts[word_counts.java == 0].sort_values(by='java').tail(6),\n",
    "           word_counts[word_counts.cplus == 0].sort_values(by='cplus').tail(6),\n",
    "           word_counts[word_counts.go == 0].sort_values(by='go').tail(6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_text_bigrams = (pd.Series(nltk.ngrams(all_text, 2))\n",
    "                      .value_counts()\n",
    "                      .head(20))\n",
    "\n",
    "top_20_javascript = (pd.Series(nltk.ngrams(python_text, 2))\n",
    "                      .value_counts()\n",
    "                      .head(20))\n",
    "\n",
    "top_20_jupyter_bigrams = (pd.Series(nltk.ngrams(jupyter_text, 2))\n",
    "                      .value_counts()\n",
    "                      .head(20))\n",
    "\n",
    "top_20_python_bigrams = (pd.Series(nltk.ngrams(python_text, 2))\n",
    "                      .value_counts()\n",
    "                      .head(20))\n",
    "\n",
    "top_20_java_bigrams = (pd.Series(nltk.ngrams(java_text, 2))\n",
    "                      .value_counts()\n",
    "                      .head(20))\n",
    "\n",
    "\n",
    "\n",
    "top_20_cplus_bigrams = (pd.Series(nltk.ngrams(cplus_text, 2))\n",
    "                      .value_counts()\n",
    "                      .head(20))\n",
    "\n",
    "top_20_go_bigrams = (pd.Series(nltk.ngrams(go_text, 2))\n",
    "                      .value_counts()\n",
    "                      .head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop where language == None\n",
    "easy_df = easy_df[easy_df.language.isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts_df = pd.DataFrame(easy_df.language.value_counts(dropna = False))\n",
    "value_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_doc_langs = list(value_counts_df[value_counts_df.language < 2].index)\n",
    "one_doc_langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in one_doc_langs:\n",
    "    easy_df = easy_df[easy_df.language != x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.fit_transform(easy_df.clean)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= easy_df.language\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify = y, test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.DataFrame(dict(acutal = y_train))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['predicted'] = lm.predict(X_train)\n",
    "test['predicted'] = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(train.acutal, train.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "80/163"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test.actual, test.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(train.acutal, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(train.predicted, train.acutal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_df = easy_df[easy_df.clean != 'error readme']\n",
    "easy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = .30, random_state = 123)\n",
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=2, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=5, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LogisticRegression().fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
